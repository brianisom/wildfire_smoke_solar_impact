---
title: "Panel Analysis of the impact of WF Smoke on Solar Gen: West US 2013-2020"
output: 
  html_document: default
  md_document:
    variant: markdown_github
---

R Markdown cheat sheet: https://www.rstudio.com/blog/the-r-markdown-cheat-sheet/

Use "?rmarkdown::_________" to look up formatting options for the YAML
header. For example, "?rmarkdown::html_document" will provide potential options
for html documents. More info on Rmarkdown anatomy can be found at
https://bookdown.org/yihui/rmarkdown-cookbook/rmarkdown-anatomy.html

Short guide to chunk options: https://bookdown.org/yihui/rmarkdown/r-code.html


#Cleaning and Combining the Data


Solar powerplant characteristics:
Download EIA form 860 data from https://www.eia.gov/electricity/data/eia860/

Monthly plant-level generation data
Download EIA for 923 data from https://www.eia.gov/electricity/data/eia923/

Install and load packages

```{r, include=FALSE}

library(easypackages)
libraries(
  "readxl",
  "ggplot2",
  "stringr",
  "rlist",
  "data.table",
  "DBI",
  "RSQLite",
  "stargazer",
  "Hmisc",
  "magrittr",
  "formattable",
  "RPostgreSQL",
  "tidyverse",
  "dbplyr",
  "pbapply",
  "stargazer",
  "quantreg",
  "olsrr",
  "faraway",
  "binaryLogic",
  "sf",
  "caret",
  "Amelia",
  "maps",
  "tidycensus",
  "reshape",
  "boot",
  "biglm",
  "tigris",
  "summarytools",
  "dplyr",
  "fs",
  "httr",
  "jsonlite",
  "usmap",
  "zoo"
)

options(scipen = 999)
```

##Monthly Solar Generation

Data for monthly solar generation is collected via the US Energy Information Agency's Open Data Application Programming Interface (API): https://www.eia.gov/opendata/

EIA APIv2 technical documentation: https://www.eia.gov/opendata/documentation.php

The following loop pulls monthly solar generation for every solar PV producer in all 12 states in the model by calling EIA's API. The data spans 2013-2020.
```{r "Retrieve monthly net generation via EIA's API"}

#Define key parameters
EIAkey <- "iPjXaaJSiyfWNALV62yg1Onb0VTuUgVHa0eVHgbx"
startdate <- "2013-01"
enddate <- "2020-12"
frequency <- "monthly"
data <- "generation"
fuel2002 <- "SUN"
primeMover <- "PV"
state <-
  c("AZ",
    "CA",
    "CO",
    "ID",
    "MT",
    "NM",
    "NV",
    "OR",
    "TX",
    "UT",
    "WA",
    "WY")
sortby <- "plantCode"
n_iter <- 12

# Initializes the progress bar
pb <- txtProgressBar(
  min = 0,
  max = n_iter,
  style = 3,
  width = 50,
  char = "="
)

j = 0
for (i in 1:12) {
  url <-
    paste(
      "https://api.eia.gov/v2/electricity/facility-fuel/data?api_key=",
      EIAkey,
      "&frequency=",
      frequency,
      "&start=",
      startdate,
      "&end=",
      enddate,
      "&data[]=",
      data,
      "&facets[state][]=",
      state[i],
      "&facets[fuel2002][]=",
      fuel2002,
      "&facets[primeMover][]=",
      primeMover,
      "&sort[0][column]=",
      sortby,
      "&sort[0][direction]=asc",
      "&length=999999",
      sep = ""
    )
  
  response <- GET(url)
  
  plant_gen_json <- fromJSON(rawToChar(response$content))
  
  plant_gen_df <- data.frame(plant_gen_json$response$data)
  plant_gen_df$year <- substr(plant_gen_df$period, 1, 4)
  plant_gen_df$month <- substr(plant_gen_df$period, 6, 7)
  
  if (j == 0) {
    plant_gen <- plant_gen_df
  }
  else{
    plant_gen <- rbind(plant_gen, plant_gen_df)
  }
  
  setTxtProgressBar(pb, i)
  
  j = j + 1
  
}

close(pb)

#Fix inconsistencies in the data
plant_gen <- plant_gen %>% 
  mutate(plantCode = as.character(
    plantCode)) %>% 
  mutate(state = ifelse(
    state == "NV" & plantCode == "57576", "NM", state)) %>% 
  mutate(state = ifelse(
    state == "NV" & plantCode == "58646", "CA", state)) %>% 
  mutate(state = ifelse(
    state == "AZ" & plantCode == "59826", "NV", state))

#Eliminate generation below 5 MW
plant_gen <-
  plant_gen[plant_gen$generation >= 5,]
```

This loop pulls characteristics for each solar PV plant in 11 of the 12 states above by calling EIA's API. The CA data is so large that it has to be run in a seperate loop.
```{r "Loop to pull plant level characteristics at 11 of 12 states"}

#Define key parameters
EIAkey <- "iPjXaaJSiyfWNALV62yg1Onb0VTuUgVHa0eVHgbx"
startdate <- "2013-01"
enddate <- "2020-12"
frequency <- "monthly"
#plantCode <- ""
fuel2002 <- "SUN"
primeMover <- "PV"
state <-
  c("AZ",
    "CO",
    "ID",
    "MT",
    "NM",
    "NV",
    "OR",
    "TX",
    "UT",
    "WA",
    "WY")
sortby <- "plantid"
n_iter <- 11

# Initializes the progress bar
pb <- txtProgressBar(
  min = 0,
  max = n_iter,
  style = 3,
  width = 50,
  char = "="
)

j = 0
for (i in 1:11) {
  url2 <-
    paste(
      "https://api.eia.gov/v2/electricity/operating-generator-capacity/data?api_key=",
      EIAkey,
      "&frequency=",
      frequency,
      "&start=",
      startdate,
      "&end=",
      enddate,
      "&data[]=county",
      "&data[]=latitude",
      "&data[]=longitude",
      "&data[]=nameplate-capacity-mw",
      "&data[]=operating-year-month",
      "&facets[stateid][]=",
      state[i],
      "&facets[energy_source_code][]=",
      fuel2002,
      "&facets[prime_mover_code][]=",
      primeMover,
      "&sort[0][column]=",
      sortby,
      "&sort[0][direction]=asc",
      "&length=999999",
      sep = ""
    )
  
  response2 <- GET(url2)
  
  plant_char_json <- fromJSON(rawToChar(response2$content))
  
  plant_char_df <- data.frame(plant_char_json$response$data)
  
  if (j == 0) {
    plant_char <- plant_char_df
  }
  else{
    plant_char <- rbind(plant_char, plant_char_df)
  }
  
  setTxtProgressBar(pb, i)
  
  j = j + 1
  
}

close(pb)

#Fix inconsistencies in the data
plant_char <- plant_char %>% 
  mutate(plantCode = as.character(
    plantCode)) %>% 
  mutate(state = ifelse(
    state == "NV" & plantCode == "57576", "NM", state)) %>% 
  mutate(state = ifelse(
    state == "NV" & plantCode == "58646", "CA", state)) %>% 
  mutate(state = ifelse(
    state == "AZ" & plantCode == "59826", "NV", state))

plant_char <- distinct(plant_char, plantid, .keep_all = TRUE)

plant_char <- subset(
  plant_char,
  select = c(
    "sector",
    "stateid",
    "entityid",
    "entityName",
    "plantid",
    "plantName",
    "balancing_authority_code",
    "balancing.authority.name",
    "status",
    "county",
    "latitude",
    "longitude",
    "nameplate.capacity.mw",
    "operating.year.month"
    
  )
)

```

Loop for CA plant characteristics
```{r "Retrieve plant-level characteristics for CA"}

#Define key parameters
EIAkey <- "iPjXaaJSiyfWNALV62yg1Onb0VTuUgVHa0eVHgbx"
startdate <- "2013-01"
enddate <- "2020-12"
frequency <- "monthly"
#plantCode <- ""
fuel2002 <- "SUN"
primeMover <- "PV"
#state <- c("AZ","CO","ID","MT","NM","NV","OR","TX","UT","WA","WY")
sortby <- "plantid"
offset <- c("0", "20001", "40001")
n_iter <- 3

# Initializes the progress bar
pb <- txtProgressBar(
  min = 0,
  max = n_iter,
  style = 3,
  width = 50,
  char = "="
)

j = 0
for (i in 1:3) {
  url2CA <-
    paste(
      "https://api.eia.gov/v2/electricity/operating-generator-capacity/data?api_key=",
      EIAkey,
      "&frequency=",
      frequency,
      "&start=",
      startdate,
      "&end=",
      enddate,
      "&data[]=county",
      "&data[]=latitude",
      "&data[]=longitude",
      "&data[]=nameplate-capacity-mw",
      "&data[]=operating-year-month",
      "&facets[stateid][]=CA",
      "&facets[energy_source_code][]=",
      fuel2002,
      "&facets[prime_mover_code][]=",
      primeMover,
      "&sort[0][column]=",
      sortby,
      "&sort[0][direction]=asc",
      "&length=20000",
      "&offset=",
      offset[i],
      sep = ""
    )
  
  response2CA <- GET(url2CA)
  
  plant_char_jsonCA <- fromJSON(rawToChar(response2CA$content))
  
  plant_char_dfCA <- data.frame(plant_char_jsonCA$response$data)
  
  if (j == 0) {
    plant_charCA <- plant_char_dfCA
  }
  else{
    plant_charCA <- rbind(plant_charCA, plant_char_dfCA)
  }
  
  setTxtProgressBar(pb, i)
  
  j = j + 1
  
}

close(pb)

plant_charCA <- distinct(plant_charCA, plantid, .keep_all = TRUE)
  

plant_charCA <- subset(
  plant_charCA,
  select = c(
    "sector",
    "entityid",
    "entityName",
    "plantid",
    "balancing_authority_code",
    "status",
    "county",
    "latitude",
    "longitude",
    "nameplate.capacity.mw",
    "operating.year.month"
    
  )
)

```

Next step is to combine all plant-level characteristics into one data frame, and then I'll use that table to add those characteristics to each row in the generation table.
```{r "Combining plant-level characteristics and building out generation table"}


plant_char_final <- rbind(plant_char, plant_charCA)

monthly_gen <-
  left_join(x = plant_gen,
            y = plant_char_final,
            by = c("plantCode" = "plantid"))

county_gen <- monthly_gen %>%
  group_by(state, county, year, month) %>%
  summarize(total_generation = sum(generation))

```

## Monthly PM 2.5 readings

The next few sections of code pull data from the Environmental Protection Agency's Air Quality System API: https://www.epa.gov/aqs. Wildfire's produce a high volume of particulate matter 2.5 (pm2.5), which I will use as a proxy for wildfire activity in a given area.

```{r  "Define functions to pull air monitor data using EPA's API"}

# Define a function to call the PM2.5 hourly data using EPA's API ----------

pm25.api.call <-
  function(bdate,
           edate,
           state,
           EPAkey = "blueswift59",
           parameter = "88101",
           frequency = "monthly",
           duration = "1",
           ...) {
    url_epa <-
      paste(
        "https://aqs.epa.gov/data/api/sampleData/byState?email=brian@thecgo.org",
        "&key=",
        EPAkey,
        "&param=",
        parameter,
        "&bdate=",
        bdate,
        "&edate=",
        edate,
        "&state=",
        state,
        "&duration=",
        duration,
        sep = ""
      )
    
    res_epa <- GET(url_epa)
    
    pm <- fromJSON(rawToChar(res_epa$content))
    
    pm_final <- data.frame(pm$Data)
    
    return(pm_final)
  }

pm25.daily.api.call <-
  function(bdate,
           edate,
           state,
           EPAkey = "blueswift59",
           parameter = "88101",
           frequency = "monthly",
           ...) {
    url_daily_epa <-
      paste(
        "https://aqs.epa.gov/data/api/dailyData/byState?email=brian@thecgo.org",
        "&key=",
        EPAkey,
        "&param=",
        parameter,
        "&bdate=",
        bdate,
        "&edate=",
        edate,
        "&state=",
        state,
        sep = ""
      )
    
    res_daily_epa <- GET(url_daily_epa)
    
    pm_daily <- fromJSON(rawToChar(res_daily_epa$content))
    
    pm_daily_final <- data.frame(pm_daily$Data)
    
    return(pm_daily_final)
  }

# Define a function to return monthly PM2.5 averages ----------

monthly.avg.pm <- function(df, ...) {
  df$day <- substr(df$date_local, 9, 10)
  df$month <- substr(df$date_local, 6, 7)
  df$year <- substr(df$date_local, 1, 4)
  
  df <- df %>% drop_na(sample_measurement)
  
  result <- df %>% group_by(state, county, year, month) %>%
    summarize(pm_measure = mean(sample_measurement))
  
  return(result)
  
}

monthly.avg.daily.pm <- function(df, ...) {
  df$day <- substr(df$date_local, 9, 10)
  df$month <- substr(df$date_local, 6, 7)
  df$year <- substr(df$date_local, 1, 4)
  
  result <- df %>% group_by(state, county, year, month) %>%
    summarize(pm_measure = mean(arithmetic_mean))
  
  return(result)
  
}

# Define a function to return daily PM2.5 averages ----------

daily.avg.pm <- function(df, ...) {
  df$day <- substr(df$date_local, 9, 10)
  df$month <- substr(df$date_local, 6, 7)
  df$year <- substr(df$date_local, 1, 4)
  
  df <- df %>% drop_na(sample_measurement)
  
  result <-
    df %>% group_by(state_code, county_code, state, county, year, month, day) %>%
    summarize(pm_measure = mean(sample_measurement))
  
  return(result)
  
} 
```

Now that those functions have been defined I can use them to pull the data I want.

```{r "Collect hourly PM2.5 data for each state and county in the sample"}


# First define the date ranges to collect

begin <-
  c(
    "20130101",
    "20140101",
    "20150101",
    "20160101",
    "20170101",
    "20180101",
    "20190101",
    "20200101"
  )

end <-
  c(
    "20131231",
    "20141231",
    "20151231",
    "20161231",
    "20171231",
    "20181231",
    "20191231",
    "20201231"
  )

# Designate each state using fips codes. Takes around an hour to run.

pmAZ <- map2_dfr(begin, end, ~ pm25.api.call(.x, .y, "04"))

pmCO <- map2_dfr(begin, end, ~ pm25.api.call(.x, .y, "08"))

pmID <- map2_dfr(begin, end, ~ pm25.api.call(.x, .y, "16"))

pmMT <- map2_dfr(begin, end, ~ pm25.api.call(.x, .y, "30"))

pmNV <- map2_dfr(begin, end, ~ pm25.api.call(.x, .y, "32"))

pmNM <- map2_dfr(begin, end, ~ pm25.api.call(.x, .y, "35"))

pmOR <- map2_dfr(begin, end, ~ pm25.api.call(.x, .y, "41"))

pmTX <- map2_dfr(begin, end, ~ pm25.api.call(.x, .y, "48"))

pmUT <- map2_dfr(begin, end, ~ pm25.api.call(.x, .y, "49"))

pmWA <- map2_dfr(begin, end, ~ pm25.api.call(.x, .y, "53"))

pmWY <- map2_dfr(begin, end, ~ pm25.api.call(.x, .y, "56"))

#Because CA is such a large dataset, it has to be broken up by county and run as a loop

#Define key parameters
EPAkey <- "blueswift59"
parameter <- "88101"  #Returns local PM 2.5 measures
frequency <- "monthly"
state <- "06"
duration <- "1"
bdate <-
  c(
    "20130101",
    "20140101",
    "20150101",
    "20160101",
    "20170101",
    "20180101",
    "20190101",
    "20200101"
  )
edate <-
  c(
    "20131231",
    "20141231",
    "20151231",
    "20161231",
    "20171231",
    "20181231",
    "20191231",
    "20201231"
  )

#Create a vector of CA counties
CA_fips <- data.table(county.fips$fips[158:215])
county <- as.character(substr(CA_fips$V1, 2, 4))

j = 0
for (i in 1:8) {
  for (c in 1:58) {
    url_epa <-
      paste(
        "https://aqs.epa.gov/data/api/sampleData/byCounty?email=brian@thecgo.org",
        "&key=",
        EPAkey,
        "&param=",
        parameter,
        "&bdate=",
        bdate[i],
        "&edate=",
        edate[i],
        "&state=",
        state,
        "&county=",
        county[c],
        "&duration=",
        duration,
        sep = ""
      )
    
    res_epa <- GET(url_epa)
    
    pmCA_JSON <- fromJSON(rawToChar(res_epa$content))
    
    pmCA_df <- data.frame(pmCA_JSON$Data)
    
    if (j == 0) {
      pmCA <- pmCA_df
    }
    else{
      pmCA <- rbind(pmCA, pmCA_df)
    }
    
    setTxtProgressBar(pb, i)
    
    j = j + 1
    
  }
}

```


```{r "Collect daily PM2.5 data for each state and county in the sample"}


# First define the date ranges to collect

begin <-
  c(
    "20130101",
    "20140101",
    "20150101",
    "20160101",
    "20170101",
    "20180101",
    "20190101",
    "20200101"
  )

end <-
  c(
    "20131231",
    "20141231",
    "20151231",
    "20161231",
    "20171231",
    "20181231",
    "20191231",
    "20201231"
  )

# Designate each state using fips codes. Takes around an hour to run.

pmAZ <- map2_dfr(begin, end, ~ pm25.daily.api.call(.x, .y, "04"))

pmCA <- map2_dfr(begin, end, ~ pm25.daily.api.call(.x, .y, "06"))
 
pmCO <- map2_dfr(begin, end, ~ pm25.daily.api.call(.x, .y, "08"))

pmID <- map2_dfr(begin, end, ~ pm25.daily.api.call(.x, .y, "16"))

pmMT <- map2_dfr(begin, end, ~ pm25.daily.api.call(.x, .y, "30"))

pmNV <- map2_dfr(begin, end, ~ pm25.daily.api.call(.x, .y, "32"))

pmNM <- map2_dfr(begin, end, ~ pm25.daily.api.call(.x, .y, "35"))

pmOR <- map2_dfr(begin, end, ~ pm25.daily.api.call(.x, .y, "41"))

pmTX <- map2_dfr(begin, end, ~ pm25.daily.api.call(.x, .y, "48"))

pmUT <- map2_dfr(begin, end, ~ pm25.daily.api.call(.x, .y, "49"))

pmWA <- map2_dfr(begin, end, ~ pm25.daily.api.call(.x, .y, "53"))

pmWY <- map2_dfr(begin, end, ~ pm25.daily.api.call(.x, .y, "56"))

```
I now have hourly pm2.5 samples from 2013 to 2020 for every air monitor in each state I am examining. Once I have those expressed as monthly averages, I can combine them with the generation data from above to form my panel data.
```{r "Creating the monthly avg PM2.5 table"}

# Create a list of each states' readings, then combine into one data table
state_pm_list <- list(pmAZ,
                      pmCA,
                      pmCO,
                      pmID,
                      pmMT,
                      pmNM,
                      pmNV,
                      pmOR,
                      pmTX,
                      pmUT,
                      pmWA,
                      pmWY)

state_pm <- rbindlist(state_pm_list)

state_pm$state <- state.abb[match(state_pm$state,
                                  state.name)]    #converts full state names to abbreviations

monthly_pm <- monthly.avg.pm(state_pm)


# Combine monthly_pm with county_gen

solar_panel_unbal <- left_join(
  county_gen,
  monthly_pm,
  by = c(
    "state" = "state",
    "county" = "county",
    "year" = "year",
    "month" = "month"
  )
)

#solar_panel <- monthly_data_full %>%
#  drop_na(pm_measure) # dropped 5,807 rows

state_county_list <- fips(state = first(solar_panel_unbal$state), county = solar_panel_unbal$county)

solar_panel_unbal %>% group_by(state,county) %>% mutate(state_county_list = fips(state = first(state), county = county)) 

state_county_list <- split(solar_panel_unbal$county,solar_panel_unbal$state)

state_county_list <- Map(fips, state_county_list, state = names(state_county_list))

state_county_list <- unsplit(state_county_list,solar_panel_unbal$county,solar_panel_unbal$state)

state_county_df <- data.table(state_county_list)

state_county_df <- arrange(state_county_df,state_county_list)

solar_panel_unbal$fips_code <- state_county_df

solar_panel_unbal$date <- paste(solar_panel_unbal$year,
                                solar_panel_unbal$month,
                                sep = "-")

#Balancing the panel

solar_panel_bal <-
  solar_panel_unbal[solar_panel_unbal$year >= 2016,] #Remove pre-2016 data (allows me to include LA and Orange County). Drops about 2700 obs

solar_panel_na <-
  solar_panel_bal[rowSums(is.na(solar_panel_bal)) > 0,] #Identifies all rows containing NA

county_na <- as.list(unique(solar_panel_na$fips_code))

solar_panel_bal <- subset(solar_panel_bal, !(fips_code %in% county_na))

# Write data to .csv for easy loading
write.csv(solar_panel_unbal, "data/solar_panel_unbal.csv")
write.csv(solar_panel_bal, "data/solar_panel_bal.csv")
write.csv(state_pm, "data/state_pm.csv")
write.csv(monthly_pm, "data/monthly_pm.csv")
write.csv(monthly_gen, "data/monthly_gen.csv")
write.csv(county_gen, "data/county_gen.csv")
```
















~~~~~~~ Parking Lot ~~~~~~








```{r "Pulling PM2.5 monitor characteristics from EPA", eval=FALSE}

#Define key parameters
EPAkey <- "blueswift59"
parameter <- "88101"  #Returns local PM 2.5 measures
bdate <- "20200101"
edate <- "20201231"
frequency <- "monthly"
state <- "06"
county <- c("067","013","005","017","009","061","077","095","113","101")
n_iter <- 10
  
# Initializes the progress bar
pb <- txtProgressBar(min = 0,
                     max = n_iter,
                     style = 3,
                     width = 50,
                     char = "=")   

j=0
for(i in 1:10) {
  
  url_epa <- 
    paste("https://aqs.epa.gov/data/api/monitors/byCounty?email=brian@thecgo.org",
          "&key=",EPAkey,
          "&param=",parameter,
          "&bdate=",bdate,
          "&edate=",edate,
          "&state=",state,
          "&county=",county[i],
          sep = "")

  res_epa <- GET(url_epa)

  pm25AZ <- fromJSON(rawToChar(res_epa$content))
  
  pm25AZ_df <- data.frame(pm25AZ$Data)
  
    if (j == 0){
      pm25AZ_final <- pm25AZ_df
   }
    else{
      pm25AZ_final <- rbind(pm25AZ_final, pm25AZ_df)
    }
  
  setTxtProgressBar(pb, i)
  
  j = j+1

}

close(pb)

plant_char <- subset(plant_char, 
                       select = c(
                         "sector",
                         "entityid",
                         "entityName",
                         "plantid",
                         "balancing_authority_code",
                         "status",
                         "county",
                         "latitude",
                         "longitude",
                         "nameplate.capacity.mw",
                         "operating.year.month"
    
))


```



```{r EIA API v1 example, eval=FALSE}

#Call multiple series using a for loop
j = 0
for(i in plantID.AZ$Plant.Id) {
  
  url <- 
    paste("https://api.eia.gov/series/?api_key=",EIAkey,
          "&series_id=ELEC.PLANT.GEN.",i,"-SUN-PV.M",sep = ""
               )
  
  res <- GET(url)
  
  json_data.AZ <- fromJSON(rawToChar(res$content), flatten = TRUE
                        )
  APIdata.AZ <- data.frame(json_data.AZ$series$data)
  
  #Create new columns to organize the data we want
  APIdata.AZ$Year <- substr(APIdata.AZ$X1,1,4) 
  APIdata.AZ$Month <- substr(APIdata.AZ$X1,5,6)
  APIdata.AZ$Day <- 1
  APIdata.AZ$Date <- as.Date(paste(APIdata.AZ$Year, APIdata.AZ$Month, APIdata.AZ$Day, sep="-"))
  colnames(APIdata.AZ)[2] <- word(json_data.AZ$series$name, 1, sep = fixed(":"))
  #APIdata.AZ$Lat <- json_data.AZ$series$lat
  #APIdata.AZ$Lon <- json_data.AZ$series$lon
  
  APIdata.AZ <- APIdata.AZ[-c(1,5)]
  
  if (j == 0){
    APIdata.AZ.final <-APIdata.AZ
  }
  else{
    APIdata.AZ.final <- merge(APIdata.AZ.final, APIdata.AZ, by="Date")
  }
  
  j = j+1
}

#APIdata.AZ.final <- subset(APIdata.AZ.final, Date>= startdate & Date <= enddate)

write.csv(APIdata.AZ.final,"temp/APIdata.AZ.csv")
write.csv(json_data.AZ,"temp/json_data.AZ.csv")
```

Import 860 data from 2___Plant_Yyyyy and 3_3_Solar_Yyyyy (only operable plants)

```{r, eval=FALSE}

plant2020 <- read.csv("data/raw/form_860/EIA860_2020_plant.csv")

solar2020 <- read.csv("data/raw/form_860/EIA860_2020_solar.csv")

```

Remove unnecessary columns from plant2020

```{r, eval=FALSE}

plant2020 <- subset(plant2020, select = c(Plant.Code,
                                          Plant.Name,
                                          Street.Address,
                                          City,
                                          State,
                                          Zip,
                                          County,
                                          Latitude,
                                          Longitude
))

```
Combine form 860 data using Plant Id

```{r, eval=FALSE}

plantchar2020 <- inner_join(x = solar2020, y = plant2020, by = "Plant.Code")

```

Remove unwanted info by creating a subset of imported data

Check if new joined dataset is matched correctly. If utility IDs and counties match,then duplicates are removed and a simpler dataset is created.

```{r, eval=FALSE}

if(all(plantchar2020$Utility.ID.x == plantchar2020$Utility.ID.y)
   &(all(plantchar2020$County.x == plantchar2020$County.y))
    ){simple_plantchar2020 <- plantchar2020[!duplicated(as.list(plantchar2020))]
    }else print("MISMATCH")

```

Remove unwanted columns

```{r, eval=FALSE}

plantchar2020 <- subset(plantchar2020, 
                        select = -c(Ash.Impoundment., 
                                    Ash.Impoundment.Lined.,
                                    Ash.Impoundment.Status, 
                                    Natural.Gas.LDC.Name,
                                    Natural.Gas.Pipeline.Name.1, 
                                    Natural.Gas.Pipeline.Name.2,
                                    Natural.Gas.Pipeline.Name.3, 
                                    Pipeline.Notes,
                                    Natural.Gas.Storage,
                                    Liquefied.Natural.Gas.Storage
))

```

Import form 923 generation data for years 2013-2020:

Create a vector for each file name
(NOTE: THE 2013 DATA HAS SLIGHTLY DIFFERENT COLUMN HEADINGS, I CHANGED THEM
MANUALLY IN EXCEL TO MATCH 2014-2020)

```{r, eval=FALSE}

form923_paths <- fs::dir_ls("data/raw/form_923")
form923_paths

```

Write a loop that will read in all files

```{r, eval=FALSE}

list_form923 <- list()

for (i in seq_along(form923_paths)) {
    list_form923[[i]] <- read.csv(
      file = form923_paths[[i]], fileEncoding = 'UTF-8-BOM'
    )
}

list_form923 <- set_names(list_form923, form923_paths)

```

Eliminate all non-utility and non-solar generation from each

```{r, eval=FALSE}

pvlist_form923 <- lapply(list_form923, function(x)
                         filter(x, NAICS.Code == "22",
                                Reported.Prime.Mover == "PV"))

```

Get rid of unnecessary columns of data

```{r, eval=FALSE}

simplepvlist_form923 <- lapply(pvlist_form923, function(x)
                              subset(x, select = c(Plant.Id, 
                                                   Plant.Name, 
                                                   Plant.State, 
                                                   Census.Region, 
                                                   NERC.Region, 
                                                   Netgen.January, 
                                                   Netgen.February,	
                                                   Netgen.March, 
                                                   Netgen.April,	
                                                   Netgen.May, 
                                                   Netgen.June,	
                                                   Netgen.July, 
                                                   Netgen.August,	
                                                   Netgen.September,	
                                                   Netgen.October,	
                                                   Netgen.November,	
                                                   Netgen.December,	
                                                   YEAR)))

```

Combine each annual form 923  data set to form one complete table 

```{r, eval=FALSE}

monthlygen <- simplepvlist_form923 %>% reduce(full_join, by="Plant.Id")
write.csv(monthlygen, "temp/monthlygen.csv")

```

Combine form 923 data with form 860 data by matching plant code with plant id

```{r, eval=FALSE}

monthlygen2 <- left_join(x = monthlygen, y = plant2020, by = c("Plant.Id" = "Plant.Code"))
write.csv(monthlygen2, "temp/monthlygen2.csv")

```

Attempt to convert from wide to long

```{r, eval=FALSE}

setDT(monthlygen2)
longmonthlygen <- melt(monthlygen2, id.vars=c("County"))
write.csv(longmonthlygen, "temp/longmonthlygen.csv")

```

Remove duplicates created by multiple generator ids

```{r, eval=FALSE}

spv2020data <- distinct(pv2020data, Plant.Id, .keep_all = TRUE)

```

Remove unnecessary data columns

```{r, eval=FALSE}

cpv2020data <- subset(spv2020data, select = c(Plant.Id, Plant.Name,
                                             Census.Region, NERC.Region.x,
                                             Respondent.Frequency, Netgen.January,	
                                             Netgen.February,	Netgen.March,	Netgen.April,	
                                             Netgen.May,	Netgen.June,	Netgen.July,	
                                             Netgen.August,	Netgen.September,	Netgen.October,	
                                             Netgen.November,	Netgen.December,	
                                             YEAR,	State.x,
                                             County.x,	Generator.ID,	Status,
                                             Nameplate.Capacity..MW.,	
                                             Operating.Year,	Street.Address,	
                                             City,	Zip,	Latitude,	Longitude))

```

Set cpv2020data as a data table

```{r, eval=FALSE}

setDT(cpv2020data)

```

Convert data from wide to long form

```{r, eval=FALSE}

Wide2020 <- melt(cpv2020data,
                 measure.vars = c("Netgen.January",	"Netgen.February","Netgen.March",	
                                  "Netgen.April",	"Netgen.May",	"Netgen.June","Netgen.July",	
                                  "Netgen.August","Netgen.September","Netgen.October",	
                                  "Netgen.November",	"Netgen.December"),
                 variable.name = "Month",
                 value.name = "Generation")

```